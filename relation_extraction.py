import jsonimport spacy
import mathfrom spacy_bi_converter 
import main
# 1 INITIALIZING SPACY
nlp = spacy.load("en_core_web_sm")
# 2 MAPPING ALL ENTITY TYPE
entity_categories = {'e_1': 'Units', 'e_2': 'Magnitude', 'e_3': 'Definition', 'e_4': 'Variable', 'e_5': 'O', 'e_10': 'Equation'}chapter = 'Chapter_10'    #chapter = 'Chapter 10'text_file = open('DataSet/' + chapter + '_Text.txt', encoding='utf-8')json_file = open('DataSet/' + chapter + '_JSON.json', encoding='utf-8')# 4 EXTRACTING TEXT FILE CONTENTStfile_content = [line for line in text_file if line != "\n"]  # list of sentencestfile_content = [line.replace("\n", "  ") for line in tfile_content]full_text = "".join(tfile_content)len_each_sentence = [0] + [len(item) for item in tfile_content]sentence_start_indexes = [len_each_sentence[0]]for i in range(1, len(len_each_sentence)):    sentence_start_indexes.append(sentence_start_indexes[-1] + len_each_sentence[i])sentence_idx_range = []  # index ranges of each sentencefor i in range(1, len(sentence_start_indexes)):    sentence_idx_range.append((sentence_start_indexes[i - 1], sentence_start_indexes[i]))sentence_start_indexes = sentence_start_indexes[:-1]  # truncates this list# for item in sentence_idx_range:#     print(full_text[item[0]: item[1]])# 5 EXTRACTING JSON FILE CONTENTSjfile_content = json.load(json_file)entity_data = jfile_content['entities']relations_entity_pairs = [{'text': data['offsets'][0]['text'], 'start': data['offsets'][0]['start'],                           'end': data['offsets'][0]['start'] + len(data['offsets'][0]['text']),                           'tag': entity_categories[data['classId']]} for data in entity_data]entity_index_tags = [{'text': data['offsets'][0]['text'], 'start': data['offsets'][0]['start'],                      'end': data['offsets'][0]['start'] + len(data['offsets'][0]['text']),                      'tag': entity_categories[data['classId']]} for data in entity_data]# items to deletedel len_each_sentencedel entity_data# checkpoint# for item in entity_index_tags:#     print(('entities', full_text[item['start']: item['end']], item['start']))    # print(item)# for item in sentence_idx_range:#    print(('full sentence', full_text[item[0]:item[1]]))""" RELATIONS  """#relation_categories = {'r_8': 'Definition_Variable', 'r_9': 'Units_Magnitude', 'r_11': 'Definition_Units',#                       'r_13': 'Variable_Units', 'r_14': 'Variable_Magnitude', 'r_15': 'Equation_Definition'}# 'r_15','r_14', 'r_13', 'r_9'relation_categories = {'r_8': 'Definition_Variable', 'r_9': 'Units_Magnitude',                       'r_13': 'Variable_Units', 'r_14': 'Variable_Magnitude'}relations_data = jfile_content['relations']all_relations = [item['classId'] for item in relations_data]pairs = [x['entities'] for x in relations_data]entity_pairs = []for item in pairs:    new_item = []    for x in item:        new_x = []        if 'e_10' in x:            new_x.append(x[10:])            new_x.append('e_10')        else:            new_x.append(x[9:])            new_x.append(x[5:8])        pair = tuple(new_x[0].split(","))        # int_pair = pair        int_pair = (tuple([int(x) for x in pair]), new_x[1])        new_item.append(int_pair)    entity_pairs.append(new_item)relations_entity_pairs = [(x[0][0], x[0][1], x[1][0], x[1][1], y) for (x, y) in zip(entity_pairs, all_relations)]relations_entity_pairs.sort()remove_rels_cats = ['r_11', 'r_15' ]remove_rels_idx = []for item in relations_entity_pairs:    if item[4] in remove_rels_cats:        # print(item)        remove_rels_idx.append(relations_entity_pairs.index(item))        #relations_entity_pairs.remove(item)    #else:        #print(item[-1])remove_rels_idx.reverse()for item in remove_rels_idx:    del relations_entity_pairs[item]encompassing = []part_of = []encompassing_index = []to_delete = []for item in relations_entity_pairs:    i = 0    while i <= len(relations_entity_pairs) - 1:        rel_here = relations_entity_pairs[i]        entity1 = rel_here[0]        entity2 = rel_here[1]        h_t = [0, 1]  # whether they are head or tails        for dsg in h_t:            # shorter entity is in between but not at the start or end of the the longer entity            if rel_here[dsg][0] < item[dsg][0] and item[dsg][1] < rel_here[dsg][1] or \                    rel_here[dsg][0] == item[dsg][0] and item[dsg][1] < rel_here[dsg][1] or \                    rel_here[dsg][0] < item[dsg][0] and item[dsg][1] == rel_here[dsg][1]:                if item not in part_of:                    part_of.append(item)                if rel_here not in encompassing:                    encompassing.append(rel_here)                if i not in encompassing_index:                    encompassing_index.append(i)            # shorter entity is at the start of the longer entity            """if rel_here[dsg][0] == item[dsg][0] and item[dsg][1] < rel_here[dsg][1]:                if item not in part_of:                    part_of.append(item)                if rel_here not in encompassing:                    encompassing.append(rel_here)            # shorter entity is at the end of the longer entity            if rel_here[dsg][0] < item[dsg][0] and item[dsg][1] == rel_here[dsg][1]:                if item not in part_of:                    part_of.append(item)                if rel_here not in encompassing:                    encompassing.append(rel_here)"""        i = i + 1# we remove from the master list all relations with entities that encompass other entitiesencompassing_index.reverse()for item in encompassing_index:    relations_entity_pairs.remove(relations_entity_pairs[item])del all_relationsdef grouper(rel_ent_pairs):    grped_rel = [[{'head': full_text[x[0][0]:  x[0][1] + 1], 'head_start': x[0][0], 'head_end': x[0][1] + 1,                   'tag_1': entity_categories[x[1]],                   'child': full_text[x[2][0]: x[2][1] + 1], 'child_start': x[2][0], 'child_end': x[2][1] + 1,                   'tag_2': entity_categories[x[3]],                   'relationLabel': relation_categories[x[4]]}                  for x in rel_ent_pairs                  if range[0] < x[0][0] < range[1]] for range in sentence_idx_range]    for idx in range(len(grped_rel)):        for rel in grped_rel[idx]:            rel['head_start'] = rel['head_start'] - sentence_start_indexes[idx]            rel['head_end'] = rel['head_end'] - sentence_start_indexes[idx]            rel['child_start'] = rel['child_start'] - sentence_start_indexes[idx]            rel['child_end'] = rel['child_end'] - sentence_start_indexes[idx]            rel['sentence_number'] = idx    return grped_relgrped_rel = grouper(relations_entity_pairs)encompassing = grouper(encompassing)encompassing = []grped_rels = grped_rel + [x for x in encompassing if x != []]def duplicate_breaker(grouped_rel):    all_new_group = []    for group in grouped_rel:        new_group = []        for rel in group:            i = 0            while i <= len(group) - 1:                compare = group[i]                if rel['head'] in compare['head'] and len(rel['head']) != len(                        compare['head']):  # rel head is a substring of compare                    if rel in group:                        group.remove(rel)                    if rel not in new_group:                        new_group.append(rel)                    # print('A-HEAD-HEAD', rel['head'], 'SEP', compare['head'], rel['head_start'], compare['head_start'])                if rel['child'] in compare['head'] and len(rel['child']) != len(compare['head']):                    # print('B- CHILD-HEAD', rel['child'], 'SEP', compare['head'], rel['child_start'], compare['head_start'])                    if rel in group:                        group.remove(rel)                    if rel not in new_group:                        new_group.append(rel)                if rel['child'] in compare['child'] and len(rel['child']) != len(compare['child']):                    # print('C- CHILD-CHILD', rel['child'], 'SEP', compare['child'], rel['child_start'], compare['child_start'])                    if rel in group:                        group.remove(rel)                    if rel not in new_group:                        new_group.append(rel)                if rel['head'] in compare['child'] and len(rel['head']) != len(compare['child']):                    # print('D- HEAD-CHILD', rel['head'], 'SEP', compare['child'], rel['head_start'], compare['child_start'])                    if rel in group:                        group.remove(rel)                    if rel not in new_group:                        new_group.append(rel)                if rel['head'] == compare['head'] and rel['head_start'] != compare['head_start']:                    # print('E- HEAD-HEAD', rel['head'], 'SEP', compare['head'], rel['head_start'], compare['head_start'])                    if rel in group:                        group.remove(rel)                    if rel not in new_group:                        new_group.append(rel)                if rel['child'] == compare['child'] and rel['child_start'] != compare['child_start']:                    if rel in group:                        group.remove(rel)                    if rel not in new_group:                        new_group.append(rel)                    # print('F- CHILD-CHILD', rel['child'], 'SEP', compare['child'], rel['child_start'], compare['child_start'])                if rel['head'] == compare['child'] and rel['head_start'] != compare['child_start']:                    if rel in group:                        group.remove(rel)                    if rel not in new_group:                        new_group.append(rel)                    # print('G- HEAD-CHILD', rel['head'], 'SEP', compare['child'], rel['head_start'], compare['child_start'])                if rel['child'] == compare['head'] and rel['child_start'] != compare['head_start']:                    if rel in group:                        group.remove(rel)                    if rel not in new_group:                        new_group.append(rel)                    # print('H- CHILD=HEAD', rel['child'], 'SEP', compare['head'], rel['child_start'], compare['head_start'])                i = i + 1        # print(len(new_group), [(x['head'], x['head_start'], x['child'], x['child_start']) for x in new_group])        # all_new_group.append([x for x in new_group if x != []])    # print(len(all_new_group))    all_new_group = [x for x in all_new_group if x != []]    return all_new_groupgrped_rels = [x for x in grped_rels if x != []]tokenized_sentences = [[str(tok) for tok in nlp(sentence)] for sentence in tfile_content]all_positions = []for idx in range(len(tokenized_sentences)):    tokenized_sentence = tokenized_sentences[idx]    full_sentence = tfile_content[idx]    index = 0    positions = []    for i in tokenized_sentence:        loc = full_sentence.find(i)        positions.append(loc + index)        index += len(i) + loc        full_sentence = full_sentence[len(i) + loc:]    all_positions.append(positions)all_positions = [all_positions[x[0]['sentence_number']] for x in grped_rels]def dictionary_completer(grouped_relations):    for idx in range(len(all_positions)):        position = all_positions[idx]        group = grouped_relations[idx]        # print(group)        # print(position)        for relation in group:            if relation['head_start'] in position:                relation['head_start_position'] = position.index(relation['head_start'])                relation['head_end_position'] = relation['head_start_position'] + len(nlp(relation['head'])) - 1            if relation['child_start'] in position:                relation['child_start_position'] = position.index(relation['child_start'])                relation['child_end_position'] = relation['child_start_position'] + len(nlp(relation['child'])) - 1            else:                group.remove(relation)        for relation in group:            if 'head_start_position' not in relation or 'child_start_position' not in relation:                group.remove(relation)    for group in grouped_relations:        if len(group) == 1 and len(group[0]) < 14:            # print(group)            grouped_relations.remove(group)            # print(group)    for idx in range(len(grouped_relations)):        group = grouped_relations[idx]        for relation in group:            # print(relation)            relevant_relation = {'head': relation['head_start_position'], 'child': relation['child_start_position'],                                 'relationLabel': relation['relationLabel']}            enti_head = {'text': relation['head'], 'start': relation['head_start'], 'end': relation['head_end'],                         'token_start': relation['head_start_position'], 'token_end': relation['head_end_position'],                         'entityLabel': relation['tag_1']}            enti_child = {'text': relation['child'], 'start': relation['child_start'], 'end': relation['child_end'],                          'token_start': relation['child_start_position'],                          'token_end': relation['child_end_position'],                          'entityLabel': relation['tag_2']}            relation['final_grouping'] = relevant_relation            relation['head_entity'] = enti_head            relation['child_entity'] = enti_child    return grouped_relationsdef group_breaker(grouped_rel):    all_group = []    for group in grouped_rel:        length = len(group)        division = math.floor(length / 4)        # print("sentence", length)        if length > 4:            for i in range(division):                # print(i)                div = group[i * 4:(i + 1) * 4]                all_group.append(div)            if length % 4 != 0:                all_group.append(group[division * 4:])        else:            all_group.append(group)    return all_groupdef dictionary_breaker(grouped_rel):    all_tokens = []    all_relations = []    all_documents = []    for i in range(len(grouped_rel)):        group = grouped_rel[i]        tokens = []        relations = []        document = []        for rel in group:            # print(rel)            if rel['head_entity'] not in tokens:                tokens.append(rel['head_entity'])            if rel['child_entity'] not in tokens:                tokens.append(rel['child_entity'])            if rel['final_grouping'] not in relations:                relations.append(rel['final_grouping'])            if tfile_content[rel['sentence_number']] not in document:                document.append(tfile_content[rel['sentence_number']])        all_tokens.append(tokens)        all_relations.append(relations)        all_documents.extend(document)    return all_relations, all_tokens, all_documents
grped_rels = dictionary_completer(grped_rels)grped_rels = group_breaker(grped_rels)grped_rels = [x for x in grped_rels if x != []]all_relations, all_entities, all_documents = dictionary_breaker(grped_rels)all_documents_en = tfile_contentALL_DATA = [(x, y, z) for (x, y, z) in zip(all_documents, all_entities, all_relations)]ALL_DATA = [x for x in ALL_DATA if x[-1] != []]ALL_DATA = [{'document': x[0], 'tokens': x[1], 'relations': x[2]} for x in ALL_DATA]dir_path = 'DataSet/final032822/relations_'+chapterwith open(dir_path+'.txt', 'w') as f:        json.dump(ALL_DATA, f, indent=2)        print("Training File Created for " + chapter)ann = dir_path+'.txt'train_file = dir_path+ '.spacy'dev_file = 'path_to/relations_dev.spacy'test_file = 'path_to/relations_test.spacy'main(ann, train_file, dev_file, test_file)
